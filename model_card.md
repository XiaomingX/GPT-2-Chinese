# GPT-2模型卡片

最后更新时间：2019年11月

受《模型报告用模型卡片（Mitchell等人）》启发，我们提供了关于所发布的GPT-2系列模型的相关信息。


## 模型详情

该模型由OpenAI的研究人员开发，旨在帮助我们理解语言模型的能力如何随模型规模（按参数数量计算）以及超大规模互联网数据集（WebText）的变化而扩展。

### 模型日期
2019年2月，训练数据截止到2017年底。

### 模型类型
语言模型

### 模型版本
15亿参数：这是第四个也是最大的GPT-2版本。我们还发布了1.24亿、3.55亿和7.74亿参数的模型。

### 更多信息的论文或其他资源
[博客文章](https://openai.com/blog/better-language-models/) 和 [论文](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### 关于模型的问题或意见请发送至
请使用此 [Google表单](https://forms.gle/A7WBSbTY2EkKdroPA)


## 预期用途

### 主要预期用途
这些模型的主要预期用户是**人工智能研究人员和从业者**。

我们主要设想研究人员将利用这些语言模型来更好地理解大规模生成式语言模型的行为、能力、偏见和局限性。

### 次要用途
我们认为以下次要使用场景是可能的：

- **写作辅助**：语法辅助、自动补全（适用于普通散文或代码）
- **创意写作与艺术**：探索虚构文本的生成；辅助诗歌和其他文学艺术创作
- **娱乐**：游戏制作、聊天机器人开发以及趣味内容生成

### 超出范围的使用场景
由于像GPT-2这样的大规模语言模型无法区分事实与虚构，我们不支持需要生成文本为真实内容的使用场景。

此外，像GPT-2这样的语言模型会反映其训练数据中固有的偏见，因此我们不建议将其部署到与人类交互的系统中，除非部署者先针对预期使用场景对相关偏见进行研究。我们发现7.74亿参数和15亿参数的模型在性别、种族和宗教偏见测试中没有统计学上的显著差异，这意味着所有版本的GPT-2在涉及人类属性相关的敏感使用场景中都应保持同等程度的谨慎。


## 评估数据

### 数据集
该模型在WebText数据集上进行训练和评估，该数据集包含Reddit社交网络用户发布的4500万个链接的文本内容。WebText的数据来源于Reddit的外部链接，而非直接取自Reddit平台本身。在生成数据集之前，我们使用了一个黑名单，确保不会从包含色情或其他冒犯性内容的多个子版块中采样。

为了让大家了解GPT-2的训练数据构成，我们发布了[一份列表](domains.txt)，包含WebText中出现的前1000个域名及其出现频率。WebText中按数量排名前15的域名是：Google、Archive、Blogspot、GitHub、NYTimes、Wordpress、Washington Post、Wikia、BBC、The Guardian、eBay、Pastebin、CNN、Yahoo!和Huffington Post。

### 动机
WebText的创建动机是构建一个互联网规模的异构数据集，用于测试大规模语言模型。WebText过去（现在也是）主要用于研究目的，而非生产用途。

### 注意事项和建议
由于GPT-2是一个互联网规模的语言模型，目前很难确定可以通过哪些规范的测试程序来全面理解其能力，以及其训练数据如何影响其广泛的输出。我们建议研究人员深入研究模型的这些方面并分享结果。

此外，正如我们在讨论模型潜在误用问题时所指出的，目前尚不清楚检测这些模型输出的长期动态是什么。我们通过简单分类器、零样本和微调方法进行了[内部基于机器学习的自动检测研究](https://github.com/openai/gpt-2-output-dataset/tree/master/detector)。我们微调的检测器模型准确率达到了约95%。然而，没有一种检测方法是万能的；基于机器学习的自动检测、人工检测、人机协作以及基于元数据的检测等方法可以结合使用，以提高分类的可信度。如今开发更好的检测方法将帮助我们更好地理解未来的模型，并可能帮助我们提前判断检测方法最终是否会失效。